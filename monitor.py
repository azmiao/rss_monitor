import datetime
import os
from typing import Optional

import feedparser
from rocksdict import Rdict

from yuiChyan import base_db_path, CQEvent, YuiChyan, FunctionException, get_bot
from yuiChyan.service import Service
from yuiChyan.util import RSSParser


sv = Service('rss_monitor')


@sv.on_prefix(('æ·»åŠ RSSè®¢é˜…', 'å¢åŠ RSSè®¢é˜…', 'æ–°å¢RSSè®¢é˜…'))
async def add_rss_url(bot: YuiChyan, ev: CQEvent):
    rss_url = str(ev.message).strip()
    group_id = ev.group_id
    user_id = ev.user_id

    if not rss_url:
        raise FunctionException(ev, f'è¾“å…¥çš„RSSè®¢é˜…URLä¸ºç©º')
    rss_monitor_db = await get_database()
    rss_dict = rss_monitor_db.get(group_id, {}).get(user_id, {})
    # æ›´æ–°æ—¶é—´ä¸ºNone
    rss_dict[rss_url] = None
    rss_monitor_db[group_id][user_id] = rss_dict
    rss_monitor_db.close()
    await bot.send(ev, f'å·²æˆåŠŸè®¢é˜…ï¼š{rss_url}', at_sender=True)


@sv.on_match('æŸ¥è¯¢RSSè®¢é˜…')
async def query_rss_url_list(bot: YuiChyan, ev: CQEvent):
    group_id = ev.group_id
    user_id = ev.user_id
    rss_monitor_db = await get_database()
    rss_dict = rss_monitor_db.get(group_id, {}).get(user_id, {})
    if not rss_dict:
        raise FunctionException(ev, f'æ‚¨è¿˜æ²¡æœ‰åœ¨æœ¬ç¾¤è®¢é˜…RSSå‘¢')
    rss_url_list = list(rss_dict.keys())
    rss_monitor_db.close()
    await bot.send(ev, f'æ‚¨å·²è®¢é˜…å¦‚ä¸‹RSSï¼š\n{"\n".join(rss_url_list)}', at_sender=True)


@sv.on_prefix(('åˆ é™¤RSSè®¢é˜…', 'å–æ¶ˆRSSè®¢é˜…'))
async def add_rss_url(bot: YuiChyan, ev: CQEvent):
    rss_url = str(ev.message).strip()
    group_id = ev.group_id
    user_id = ev.user_id

    if not rss_url:
        raise FunctionException(ev, f'è¾“å…¥çš„RSSè®¢é˜…URLä¸ºç©º')
    rss_monitor_db = await get_database()
    rss_dict = rss_monitor_db.get(group_id, {}).get(user_id, {})
    if rss_url not in rss_dict:
        raise FunctionException(ev, f'æ‚¨æœªè®¢é˜…è¯¥RSS')
    rss_dict.pop(rss_url)
    rss_monitor_db[group_id][user_id] = rss_dict
    await bot.send(ev, f'å·²æˆåŠŸåˆ é™¤è®¢é˜…ï¼š{rss_url}', at_sender=True)


@sv.scheduled_job(minute='*/1')
async def monitor_schedule():
    bot = get_bot()
    rss_monitor_db = await get_database()
    for group_id in rss_monitor_db:
        group_data: dict = rss_monitor_db.get(group_id, {})
        for user_id in group_data:
            rss_dict: dict = group_data.get(user_id, {})
            # ç¬¬ä¸€æ¬¡è®¢é˜…åupdate_timeä¸ºNone
            for rss_url, update_time in rss_dict.items():
                try:
                    # æ£€æµ‹ RSS æ˜¯å¦æœ‰æ›´æ–°
                    new_update_time, new_entries = await check_rss(rss_url, update_time)

                    if new_entries:  # æœ‰æ›´æ–°
                        # æ›´æ–°æ•°æ®åº“é‡Œçš„æ›´æ–°æ—¶é—´
                        rss_dict[rss_url] = new_update_time
                        rss_monitor_db[group_id][user_id] = rss_dict
                        await bot.send(group_id=group_id, message=format_entries_message(new_entries))

                except Exception as e:
                    print(f"[ERROR] ç›‘æ§ RSS {rss_url} å¤±è´¥: {e}")


async def get_database() -> Rdict:
    """
    ç›‘æ§ä¿¡æ¯æ•°æ®åº“
    """
    rss_monitor_db = Rdict(os.path.join(base_db_path, 'rss_monitor.db'))
    return rss_monitor_db


async def check_rss(rss_url: str, update_time: Optional[str]):
    """
    æ£€æµ‹ RSS æ˜¯å¦æœ‰æ–°å†…å®¹
    :param rss_url: RSS é“¾æ¥
    :param update_time: æ•°æ®åº“ä¸­è®°å½•çš„ä¸Šæ¬¡æ›´æ–°æ—¶é—´ï¼ˆå¯èƒ½æ˜¯ Noneï¼‰
    :return: (æ–°çš„æ›´æ–°æ—¶é—´, æ–°çš„æ¡ç›®åˆ—è¡¨)
    """
    parser = RSSParser(rss_url)
    feed = parser.parse_feed()

    new_entries = []
    latest_update_time = update_time

    for entry in feed.entries:
        entry_time = parse_datetime(entry.published)

        # ç¬¬ä¸€æ¬¡è®¢é˜… || æœ‰æ–°å†…å®¹
        if update_time is None or (entry_time and entry_time > parse_datetime(update_time)):
            new_entries.append(entry)
            # åŒæ—¶æ›´æ–°æœ€æ–°æ—¶é—´
            if latest_update_time is None or (entry_time and entry_time > parse_datetime(latest_update_time)):
                latest_update_time = entry.published

    return latest_update_time, new_entries


def parse_datetime(dt_str: str) -> Optional[datetime.datetime]:
    """æŠŠ RSS çš„æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸º datetime"""
    try:
        return datetime.datetime(*feedparser.parse(dt_str).updated_parsed[:6])
    except Exception:
        try:
            return datetime.datetime.fromisoformat(dt_str)
        except Exception:
            return None


def format_entries_message(entries):
    """æŠŠæ–° RSS æ¡ç›®æ ¼å¼åŒ–ä¸ºå¯å‘é€æ¶ˆæ¯"""
    msgs = []
    for e in entries:
        msgs.append(f"ğŸ“¢ {e.title}\nğŸ”— {e.link}\nğŸ•’ {e.published}")
    return "\n\n".join(msgs)
